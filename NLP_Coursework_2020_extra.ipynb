{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Coursework_2020_v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "88KbEPMAmbxF",
        "outputId": "a99ee0b5-80d0-4a00-c545-ddca1a80a3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TDd4BKiQmvSg",
        "outputId": "be5ff054-e52f-495e-cad5-fa2ced155507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "import os\n",
        "import re\n",
        "import string\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import requests\n",
        "from random import randint\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "from collections import Counter\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "try:\n",
        "    from autocorrect import Speller\n",
        "except:\n",
        "    !pip install autocorrect\n",
        "    from autocorrect import Speller\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "spell_check_dict = dict()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting autocorrect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/b0/a1d628fa192e8ebf124b4cebc2a42b4e3aa65b8052fdf4888e04fadf3e8d/autocorrect-1.1.0.tar.gz (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-1.1.0-cp36-none-any.whl size=1810772 sha256=3ef900c6e0602ac745c1381fbd3e00152b76484e86c27bd23d2a82755b0cb1ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/7f/b1/527522820ae623df6a2dbe14f778d23adaea4bebe43f7ebcfe\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-1.1.0\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZHnD-KvWnKka",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "class RelevanceScorePrediction:\n",
        "    def __init__(self, settings):\n",
        "        self.path_to_files = settings['path_to_files']        \n",
        "        self.train_path = self.path_to_files + \"/train.csv\"\n",
        "        self.test_path = self.path_to_files + \"/test.csv\"\n",
        "        self.product_descriptions_path = self.path_to_files + \"/product_descriptions.csv\"\n",
        "        self.attributes_path = self.path_to_files + \"/attributes.csv\"\n",
        "        \n",
        "        self.df_train = pd.read_csv(self.train_path, encoding='ISO-8859-1', header=0)\n",
        "        self.df_test = pd.read_csv(self.test_path, encoding='ISO-8859-1', header=0)\n",
        "        self.df_product_desc = pd.read_csv(self.product_descriptions_path, header=0)\n",
        "        self.df_product_attr = pd.read_csv(self.attributes_path, header=0)\n",
        "\n",
        "    # Functions that reads the dataframes  \n",
        "    def reads_and_merges(self):\n",
        "        print('The shape of train is:', self.df_train.shape)\n",
        "        print('The info of train is: ')\n",
        "        print(self.df_train.info())\n",
        "        self.len_train = self.df_train.shape[0]\n",
        "        print('The len_train is: ')\n",
        "        print(self.len_train)\n",
        "        \n",
        "        print('\\n The shape of test is:', self.df_test.shape)\n",
        "        print('The info of test is: ')\n",
        "        print(self.df_test.info())\n",
        "        \n",
        "        print('\\n The shape of product description is: ', self.df_product_desc.shape)\n",
        "        print('The info of product description is: ')\n",
        "        print(self.df_product_desc.info())\n",
        "\n",
        "        print('\\n The shape of product attributes is: \\n', self.df_product_attr.shape)\n",
        "        print('The null values of product attributes before drop are: \\n', self.df_product_attr.isnull().sum())\n",
        "\n",
        "        self.df_product_attr = self.df_product_attr.dropna(how=\"all\")\n",
        "        self.df_product_attr[\"product_uid\"] = self.df_product_attr[\"product_uid\"].astype(\"int64\")\n",
        "        print('The null values of product attributes after drop are: \\n', self.df_product_attr.isnull().sum())\n",
        "        \n",
        "        # merge train with test\n",
        "        self.df_train_test = pd.concat([self.df_train, self.df_test], axis=0, ignore_index=True)\n",
        "        print('The shape of train-test dataframe is: ', self.df_train_test.shape)\n",
        "        \n",
        "        # For attributes table, we are only interested in brand names which could be included in search queries.\n",
        "        self.df_product_brand = self.df_product_attr[self.df_product_attr.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"})\n",
        "        print('The shape of product_brand is: ', self.df_product_brand.shape)\n",
        "        \n",
        "        # merge train_test with product attributes\n",
        "        self.df_train_test_brands = pd.merge(self.df_train_test, self.df_product_brand, how='left', on='product_uid')\n",
        "        print('The shape of train_test_brands is: ', self.df_train_test_brands.shape)\n",
        "        print('The info of train_test_brands is: ')\n",
        "        print(self.df_train_test_brands.info())\n",
        "        self.df_train_test_brands[\"brand\"] = self.df_train_test_brands[\"brand\"].astype(str)\n",
        "        self.df_train_test_brands.fillna(\"unknown\", inplace=True)\n",
        "        print('The info of train_test_brands after filling null values is: ')\n",
        "        print(self.df_train_test_brands.info())\n",
        "        \n",
        "        return self.df_train, self.df_test, self.df_product_desc, self.df_product_attr, self.df_train_test, self.df_train_test_brands\n",
        "\n",
        "    def preprocessing(self):\n",
        "        self.df_train, self.df_test, self.df_product_desc, self.df_product_attr, self.df_train_test, self.df_train_test_brands = self.reads_and_merges()\n",
        "        \n",
        "        # Function to perform simole regex\n",
        "        def simple_regex(text, regex1, sub1, regex2, sub2, regex3, sub3):\n",
        "            text = re.sub(regex1, sub1, text) # add space after . if it doesn't exist.also avoid add space after the last .\n",
        "            text = re.sub(regex2, sub2, text) # do this also for ;\n",
        "            text = re.sub(regex3, sub3, text) # add space Capital words that are in the form textTex\n",
        "            return text\n",
        "\n",
        "        # Perfom simple regex\n",
        "        print('Perform text corrections with regex')\n",
        "        start_regex = time.time()\n",
        "        regex1 = r\"\\.(?!\\s)(?!$)\"\n",
        "        sub1 = \". \"\n",
        "        regex2 = r\"\\;(?!\\s)(?!$)\"\n",
        "        sub2 = \"; \"\n",
        "        regex3 = r\"([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))\"\n",
        "        sub3 = r\"\\1 \"\n",
        "        self.df_train_test_brands['search_term'] = self.df_train_test_brands['search_term'].map(lambda x: simple_regex(x, regex1, sub1, regex2, sub2, regex3, sub3))\n",
        "        print(\"product_title...\")\n",
        "        self.df_train_test_brands['product_title'] = self.df_train_test_brands['product_title'].map(lambda x: simple_regex(x, regex1, sub1, regex2, sub2, regex3, sub3))\n",
        "        print(\"brand...\")\n",
        "        self.df_train_test_brands['brand'] = self.df_train_test_brands['brand'].map(lambda x: simple_regex(x, regex1, sub1, regex2, sub2, regex3, sub3))\n",
        "        print(\"product_description...\")\n",
        "        print('initial: \\n', self.df_product_desc['product_description'][1])\n",
        "        self.df_product_desc['product_description'] = self.df_product_desc['product_description'].map(lambda x: simple_regex(x, regex1, sub1, regex2, sub2, regex3, sub3))\n",
        "        print('after regex: \\n', self.df_product_desc['product_description'][1])\n",
        "        end_regex = time.time()\n",
        "        print(\"Simple regex finished in \", (end_regex - start_regex), \"seconds\")\n",
        "\n",
        "        # Function to correct measurement units\n",
        "        def measurement_unit_correction(text):\n",
        "            \"\"\"\n",
        "            This function preprocess a string. Corrects measurement units.\n",
        "            Input: A string\n",
        "            Output: A string with corrected measurements\n",
        "            Example: text = measurement_unit_correction(text)\n",
        "            \"\"\"\n",
        "            if isinstance(text, str):\n",
        "\n",
        "                metric = text.lower()\n",
        "\n",
        "                metric = metric.replace(\"centimeters\",\" cm.\")    \n",
        "\n",
        "                metric = metric.replace(\"millimeters\",\" mm.\")\n",
        "\n",
        "                metric = metric.replace(\"'\",\" in. \") \n",
        "                metric = metric.replace(\"inches\",\" in. \") \n",
        "                metric = metric.replace(\"inch\",\" in. \")\n",
        "                metric = metric.replace(\"''\",\" ft. \") \n",
        "                metric = metric.replace(\"feet\",\" ft. \") \n",
        "                metric = metric.replace(\"foot\",\" ft. \") \n",
        "                metric = metric.replace(\"sq ft\",\" sq.ft. \") \n",
        "                metric = metric.replace(\"sqft \",\" sq.ft. \")\n",
        "                metric = metric.replace(\"sq. ft\",\" sq.ft. \") \n",
        "                metric = metric.replace(\"sq ft.\",\" sq.ft. \") \n",
        "                metric = metric.replace(\"sq feet\",\" sq.ft. \") \n",
        "                metric = metric.replace(\"square feet\",\" sq.ft. \") \n",
        "\n",
        "                metric = metric.replace(\"pounds\",\" lb. \")\n",
        "                metric = metric.replace(\"pound\",\" lb. \") \n",
        "                metric = metric.replace(\"lbs \",\" lb. \") \n",
        "                metric = metric.replace(\"lbs.\",\" lb. \") \n",
        "\n",
        "                metric = metric.replace(\" x \",\" xby \")\n",
        "                metric = metric.replace(\"*\",\" xby \")\n",
        "                metric = metric.replace(\"by\",\" xby \")\n",
        "                metric = metric.replace(\"x0\",\" xby 0 \")\n",
        "                metric = metric.replace(\"x1\",\" xby 1 \")\n",
        "                metric = metric.replace(\"x2\",\" xby 2 \")\n",
        "                metric = metric.replace(\"x3\",\" xby 3 \")\n",
        "                metric = metric.replace(\"x4\",\" xby 4 \")\n",
        "                metric = metric.replace(\"x5\",\" xby 5 \")\n",
        "                metric = metric.replace(\"x6\",\" xby 6 \")\n",
        "                metric = metric.replace(\"x7\",\" xby 7 \")\n",
        "                metric = metric.replace(\"x8\",\" xby 8 \")\n",
        "                metric = metric.replace(\"x9\",\" xby 9 \")\n",
        "                metric = metric.replace(\"0x\",\" 0 xby \")\n",
        "                metric = metric.replace(\"1x\",\" 1 xby \")\n",
        "                metric = metric.replace(\"2x\",\" 2 xby \")\n",
        "                metric = metric.replace(\"3x\",\" 3 xby \")\n",
        "                metric = metric.replace(\"4x\",\" 4 xby \")\n",
        "                metric = metric.replace(\"5x\",\" 5 xby \")\n",
        "                metric = metric.replace(\"6x\",\" 6 xby \")\n",
        "                metric = metric.replace(\"7x\",\" 7 xby \")\n",
        "                metric = metric.replace(\"8x\",\" 8 xby \")\n",
        "                metric = metric.replace(\"9x\",\" 9 xby \")\n",
        "            \n",
        "                metric = metric.replace(\"gallon\",\" gal. \")\n",
        "                metric = metric.replace(\"gallons\",\" gal. \") \n",
        "\n",
        "                metric = metric.replace(\"ounces\",\" oz. \")\n",
        "                metric = metric.replace(\"ounce\",\" oz. \")\n",
        "                \n",
        "                metric = metric.replace(\"°\",\" deg. \")\n",
        "                metric = metric.replace(\"degrees\",\" deg. \")\n",
        "                metric = metric.replace(\"degree\",\" deg. \")\n",
        "                \n",
        "                metric = metric.replace(\"volts\",\" volt. \")\n",
        "\n",
        "                metric = metric.replace(\"watts\",\" watt. \")\n",
        "                metric = metric.replace(\"watt\",\" watt. \")\n",
        "\n",
        "                metric = metric.replace(\"ampere\",\" amp. \")\n",
        "                metric = metric.replace(\"amps\",\" amp. \")\n",
        "\n",
        "                return metric\n",
        "\n",
        "        print('Measurement unit correction...')\n",
        "        start_units = time.time()\n",
        "        print('search term...')\n",
        "        self.df_train_test_brands['search_term'] = self.df_train_test_brands['search_term'].map(lambda x: measurement_unit_correction(x))\n",
        "        print(\"product_title...\")\n",
        "        self.df_train_test_brands['product_title'] = self.df_train_test_brands['product_title'].map(lambda x: measurement_unit_correction(x))\n",
        "        print(\"brand...\")\n",
        "        self.df_train_test_brands['brand'] = self.df_train_test_brands['brand'].map(lambda x: measurement_unit_correction(x))\n",
        "        print(\"product_description...\")\n",
        "        self.df_product_desc['product_description'] = self.df_product_desc['product_description'].map(lambda x: measurement_unit_correction(x))\n",
        "        end_units = time.time()\n",
        "        print(\"Measurement unit correction finished in \", (end_units - start_units), \"seconds\")\n",
        "\n",
        "        # Function to remove stopwords from a string\n",
        "        def stopwords_removal(text, cachedStopWords):\n",
        "            \"\"\"\n",
        "            This function preprocess a string. Removes stopwords.\n",
        "            Input: A string\n",
        "            Output: A string cleaned from stop_words\n",
        "            Example: text = stopwords_removal(text)\n",
        "            \"\"\"\n",
        "            if not isinstance(text, str):\n",
        "                return text\n",
        "\n",
        "            words = nltk.word_tokenize(text.lower())\n",
        "            no_stopwords = [word for word in words if word not in cachedStopWords]\n",
        "            return ' '.join(no_stopwords)\n",
        "    \n",
        "        # stopwords removal\n",
        "        print(\"Removing stopwords...\")\n",
        "        start_stopwords = time.time()\n",
        "        cachedStopWords = stopwords.words('english')\n",
        "        print('The stopwords are: ', cachedStopWords) # to see the english stopwords\n",
        "        print(\"search_term...\")\n",
        "        self.df_train_test_brands['search_term'] = self.df_train_test_brands['search_term'].map(lambda x: stopwords_removal(x,cachedStopWords))\n",
        "        print(\"product_title...\")\n",
        "        self.df_train_test_brands['product_title'] = self.df_train_test_brands['product_title'].map(lambda x: stopwords_removal(x, cachedStopWords))\n",
        "        print(\"brand...\")\n",
        "        self.df_train_test_brands['brand'] = self.df_train_test_brands['brand'].map(lambda x: stopwords_removal(x, cachedStopWords))\n",
        "        print(\"product_description...\")\n",
        "        self.df_product_desc['product_description'] = self.df_product_desc['product_description'].map(lambda x: stopwords_removal(x, cachedStopWords))\n",
        "        print(self.df_product_desc['product_description'][1])\n",
        "        end_stopwords = time.time()\n",
        "        print(\"Stopwords removal finished in \", (end_stopwords - start_stopwords), \"seconds\")\n",
        "        print(\"----------------------------------------------------\")\n",
        "\n",
        "        # Function to remove punctuations from a string\n",
        "        def punctuations_removal(text, translate_table_punctuations):\n",
        "            \"\"\"\n",
        "            This function preprocess a string. Removes punctuations.\n",
        "            Input: A string\n",
        "            Output: A string cleaned from punctuations\n",
        "            Example: text = punctuation_removal(text)\n",
        "            look also this: https://stackoverflow.com/questions/43935592/add-space-after-full-stops\n",
        "            \"\"\"\n",
        "            if not isinstance(text, str):\n",
        "                return text\n",
        "            return text.translate(translate_table_punctuations)\n",
        "\n",
        "        # punctuation removal\n",
        "        print(\"Removing punctuations...\")\n",
        "        start_punc = time.time()\n",
        "        punctuations = string.punctuation\n",
        "        print('The punctuations are: ', punctuations) # to see the punctuations\n",
        "        translate_table_punctuations = str.maketrans(\"\",\"\",punctuations)\n",
        "        print(\"search_term...\")\n",
        "        self.df_train_test_brands['search_term'] = self.df_train_test_brands['search_term'].map(lambda x: punctuations_removal(x, translate_table_punctuations))\n",
        "        print(\"product_title...\")\n",
        "        self.df_train_test_brands['product_title'] = self.df_train_test_brands['product_title'].map(lambda x: punctuations_removal(x, translate_table_punctuations))\n",
        "        print(\"brand...\")\n",
        "        self.df_train_test_brands['brand'] = self.df_train_test_brands['brand'].map(lambda x: punctuations_removal(x, translate_table_punctuations))\n",
        "        print(\"product_description...\")\n",
        "        self.df_product_desc['product_description'] = self.df_product_desc['product_description'].map(lambda x: punctuations_removal(x, translate_table_punctuations))\n",
        "        print(self.df_product_desc['product_description'][1])\n",
        "        end_punc = time.time()\n",
        "        print(\"Punctuation removal finished in \", (end_punc - start_punc), \"seconds\")\n",
        "        print(\"----------------------------------------------------\")\n",
        "\n",
        "        \n",
        "        # # Function to correct spelling errors\n",
        "        # spell = Speller(lang=\"en\")\n",
        "        # def spell_check(text):\n",
        "        #     # lower_text = text.lower()\n",
        "        #     # return spell(lower_text)\n",
        "        #     def P(word, N=sum(WORDS.values())): \n",
        "        #         \"Probability of `word`.\"\n",
        "        #         return WORDS[word] / N\n",
        "\n",
        "        #     def correction(word): \n",
        "        #         \"Most probable spelling correction for word.\"\n",
        "        #         return max(candidates(word), key=P)\n",
        "\n",
        "        #     def candidates(word): \n",
        "        #         \"Generate possible spelling corrections for word.\"\n",
        "        #         return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "        #     def known(words): \n",
        "        #         \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "        #         return set(w for w in words if w in WORDS)\n",
        "\n",
        "        #     def edits1(word):\n",
        "        #         \"All edits that are one edit away from `word`.\"\n",
        "        #         letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "        #         splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "        #         deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "        #         transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "        #         replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "        #         inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "        #         return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "        #     def edits2(word): \n",
        "        #         \"All edits that are two edits away from `word`.\"\n",
        "        #         return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
        "\n",
        "        #     lower_case_input = text.lower()\n",
        "        #     tokens = word_tokenize(lower_case_input)\n",
        "        #     corrected = [correction(token) for token in tokens]\n",
        "        #     spell_check_dict[lower_case_input] = ' '.join(corrected)\n",
        "        #     print(spell_check_dict)\n",
        "        #     # print(\"input: \", lower_case_input)\n",
        "        #     # print(\"output: \", ' '.join(corrected))\n",
        "        #     return ' '.join(corrected)\n",
        "\n",
        "        # # Spell Correction\n",
        "        # print(\"Creating vocabulary for spell correction...\")\n",
        "        # wordsArr = []\n",
        "        # vocabulary_columns = [self.df_train_test_brands[\"product_title\"], self.df_product_desc[\"product_description\"], self.df_train_test_brands[\"brand\"]]\n",
        "        # for column in vocabulary_columns:\n",
        "        #     for entry in column:\n",
        "        #         words = word_tokenize(entry.lower())\n",
        "        #         for word in words:\n",
        "        #             wordsArr.append(word)\n",
        "\n",
        "        # WORDS = Counter(wordsArr)\n",
        "        # print(\"Top 5 most common words found in description, title and brand: \", WORDS.most_common(5))\n",
        "        \n",
        "        # print(\"Spell correcting...\")\n",
        "        # start_spell = time.time()\n",
        "        # self.df_train_test_brands['search_term'] = self.df_train_test_brands['search_term'].map(lambda x: spell_check(x))\n",
        "        # end_spell = time.time()\n",
        "        # print(\"Spell correction finished in \", (end_spell - start_spell), \"seconds\")\n",
        "        # f = open('spell_check_dict.txt', 'w+')\n",
        "        # f.write(json.dumps(spell_check_dict))\n",
        "        # print(\"----------------------------------------------------\")\n",
        "\n",
        "        # Function to perform stemming\n",
        "        def simple_stemming(text, snowball_stemmer):\n",
        "            if not isinstance(text, str):\n",
        "                return text\n",
        "            tokens = word_tokenize(text.lower())\n",
        "            stemmed = [snowball_stemmer.stem(word) for word in tokens]\n",
        "            return ' '.join(stemmed)\n",
        "\n",
        "        # Perform simple stemming\n",
        "        print(\"Performing simple stemming...\")\n",
        "        start_stem = time.time()\n",
        "        snowball_stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
        "        print(\"search_term...\")\n",
        "        self.df_train_test_brands['search_term'] = self.df_train_test_brands['search_term'].map(lambda x: simple_stemming(x, snowball_stemmer))\n",
        "        print(\"product_title...\")\n",
        "        self.df_train_test_brands['product_title'] = self.df_train_test_brands['product_title'].map(lambda x: simple_stemming(x, snowball_stemmer))\n",
        "        print(\"brand...\")\n",
        "        self.df_train_test_brands['brand'] = self.df_train_test_brands['brand'].map(lambda x: simple_stemming(x, snowball_stemmer))\n",
        "        print(\"product_description...\")\n",
        "        self.df_product_desc['product_description'] = self.df_product_desc['product_description'].map(lambda x: simple_stemming(x, snowball_stemmer))\n",
        "        print(self.df_product_desc['product_description'][1])\n",
        "        end_stem = time.time()\n",
        "        print(\"Simple stemming finished in \", (end_stem - start_stem), \"seconds\")\n",
        "        \n",
        "        self.df_merged = self.df_train_test_brands.merge(self.df_product_desc, how='left', on='product_uid')\n",
        "        print('\\n The shape of train_test with products_description is: ', self.df_merged.shape)\n",
        "        print(self.df_merged.info())\n",
        "        return self.df_merged\n",
        "    \n",
        "    # Function to constract new features\n",
        "    def feature_engineering(self):\n",
        "        self.df_merged = self.preprocessing()\n",
        "        \n",
        "        # Add new columns with the length of the column\n",
        "        print(\"creating len columns...\")\n",
        "        start_length = time.time()\n",
        "        self.df_merged['len_of_query'] = self.df_merged['search_term'].map(lambda x: len(x.split())).astype(np.int64)\n",
        "        self.df_merged['len_of_title'] = self.df_merged['product_title'].map(lambda x:len(x.split())).astype(np.int64)\n",
        "        self.df_merged['len_of_description'] = self.df_merged['product_description'].map(lambda x:len(x.split())).astype(np.int64)\n",
        "        self.df_merged['len_of_brand'] = self.df_merged['brand'].apply(lambda x:len(x.split())).astype(np.int64)\n",
        "        end_length = time.time()\n",
        "        print(\"Length calculation finished in \", (end_length - start_length), \"seconds\")\n",
        "\n",
        "        # Add a product_all_info column summarizing the attributes of products seperating by TAB\n",
        "        print(\"creating combination of columns...\")\n",
        "        self.df_merged['product_all_information'] = self.df_merged['search_term'] + \"\\t\" + self.df_merged['product_title'] + \"\\t\" + self.df_merged['product_description']\n",
        "        self.df_merged['brand_helper'] = self.df_merged['search_term'] + \"\\t\" + self.df_merged['brand'] + \"\\t\" + self.df_merged['product_title']\n",
        "\n",
        "        # Function to find number of common words.\n",
        "        def num_common_words(str_1, str_2):\n",
        "            if not isinstance(str_1, str) or not isinstance(str_2, str):\n",
        "                return 0\n",
        "            return sum(int(str_2.find(word)>=0) for word in str_1.split())\n",
        "\n",
        "        # Add new columns with common words of the search term with product title and the search term with description\n",
        "        print(\"creating common_words title/description...\")\n",
        "        start_common_words = time.time()\n",
        "        self.df_merged['common_words_in_title'] = self.df_merged['product_all_information'].map(lambda x: num_common_words(x.split('\\t')[0], x.split('\\t')[1]))\n",
        "        self.df_merged['common_words_in_description'] = self.df_merged['product_all_information'].map(lambda x: num_common_words(x.split('\\t')[0], x.split('\\t')[2]))\n",
        "        self.df_merged['common_words_in_brand'] = self.df_merged['brand_helper'].map(lambda x: num_common_words(x.split('\\t')[0], x.split('\\t')[1]))\n",
        "        end_common_words = time.time()\n",
        "        print(\"Common words calculation finished in \", (end_common_words - start_common_words), \"seconds\")\n",
        "\n",
        "        # Function to find common phrase\n",
        "        def num_whole_word(str_1, str_2, i):\n",
        "            if not isinstance(str_1, str) or not isinstance(str_2, str):\n",
        "                return 0\n",
        "\n",
        "            str_1, str_2 = str_1.strip(), str_2.strip()\n",
        "            count = 0\n",
        "            while i < len(str_2):\n",
        "                i = str_2.find(str_1, i)\n",
        "                if i == -1:\n",
        "                    return count\n",
        "                else:\n",
        "                    count += 1\n",
        "                    i += len(str_1)\n",
        "            return count\n",
        "\n",
        "        # Add new columns with number of times the entire search term appears in product title and number of times the entire search term appears in product description.\n",
        "        # print(\"creating query_in_X columns...\")\n",
        "        # start_whole_word = time.time()\n",
        "        # self.df_merged['query_in_title'] = self.df_merged['product_all_information'].map(lambda x: num_whole_word(x.split('\\t')[0], x.split('\\t')[1],0))\n",
        "        # self.df_merged['query_in_description'] = self.df_merged['product_all_information'].map(lambda x: num_whole_word(x.split('\\t')[0], x.split('\\t')[2],0))\n",
        "        # self.df_merged['query_in_brand'] = self.df_merged['brand_helper'].map(lambda x: num_whole_word(x.split('\\t')[0], x.split('\\t')[1],0))\n",
        "        # end_whole_word = time.time()\n",
        "        # print(\"Whole word calculation finished in \", (end_whole_word - start_whole_word), \"seconds\")\n",
        "\n",
        "        # Add new columns with the ratio of common words in title with respect to query and ratio of common words in description with respect to query\n",
        "        print(\"creating ratio columns...\")\n",
        "        start_ratio = time.time()\n",
        "        self.df_merged['ratio_title'] = self.df_merged['common_words_in_title'] / self.df_merged['len_of_query']\n",
        "        self.df_merged['ratio_description'] = self.df_merged['common_words_in_description'] / self.df_merged['len_of_query']\n",
        "        # self.df_merged['ratio_brand'] = self.df_merged['query_in_brand'] / self.df_merged['len_of_brand']\n",
        "\n",
        "        self.df_merged['query_title_len_prop'] = self.df_merged['len_of_title'] / self.df_merged['len_of_query']\n",
        "        self.df_merged['query_desc_len_prop'] = self.df_merged['len_of_description'] / self.df_merged['len_of_query']\n",
        "        self.df_merged = self.df_merged.replace([np.inf, -np.inf], np.nan)\n",
        "        print(self.df_merged.info())\n",
        "        self.df_merged['ratio_title'].fillna(0.0, inplace = True)\n",
        "        self.df_merged['ratio_description'].fillna(0.0, inplace = True)\n",
        "        self.df_merged['query_title_len_prop'].fillna(0.0, inplace = True)\n",
        "        self.df_merged['query_desc_len_prop'].fillna(0.0, inplace = True)\n",
        "        print(self.df_merged.info())\n",
        "        end_ratio = time.time()\n",
        "        print(\"Ratio calculation finished in \", (end_ratio - start_ratio), \"seconds\")\n",
        "        \n",
        "      # Function to compute jaccard similarity\n",
        "        def jaccard_sim(str_1, str_2):\n",
        "            if not isinstance(str_1, str) or not isinstance(str_2, str):\n",
        "                return 0\n",
        "            set_1 = set(str_1.split())\n",
        "            set_2 = set(str_2.split())\n",
        "            if len(set_1.union(set_2)) == 0:\n",
        "              return 0\n",
        "            return len(set_1.intersection(set_2)) / (float(len(set_1.union(set_2))))\n",
        "\n",
        "        # Add new columns with jaccard similarity of search term and product title and search term and product description\n",
        "        print(\"creating jacard columns ....\")\n",
        "        start_jaccard = time.time()\n",
        "        self.df_merged['jaccard_search_and_title'] = self.df_merged['product_all_information'].map(lambda x: jaccard_sim(x.split('\\t')[0], x.split('\\t')[1]))\n",
        "        self.df_merged['jaccard_search_and_description'] = self.df_merged['product_all_information'].map(lambda x: jaccard_sim(x.split('\\t')[0], x.split('\\t')[2]))\n",
        "        self.df_merged['jaccard_search_and_brand'] = self.df_merged['brand_helper'].map(lambda x: jaccard_sim(x.split('\\t')[0], x.split('\\t')[1]))\n",
        "        self.df_merged['jaccard_search_and_title'] = self.df_merged['jaccard_search_and_title'].round(3)\n",
        "        self.df_merged['jaccard_search_and_description'] = self.df_merged['jaccard_search_and_description'].round(3)\n",
        "        self.df_merged['jaccard_search_and_brand'] = self.df_merged['jaccard_search_and_brand'].round(3)\n",
        "        end_jaccard = time.time()\n",
        "        print(\"Jaccard calculation finished in \", (end_jaccard - start_jaccard), \"seconds\")\n",
        "\n",
        "        # Function to compute the number of common ngrams\n",
        "        def common_ngrams(str_1, str_2, n):\n",
        "            bigrams_1 = ngrams(str_1.lower().split(), n)\n",
        "            bigrams_2 = ngrams(str_2.lower().split(), n)\n",
        "            common = []\n",
        "            for grams_1 in bigrams_1:\n",
        "                if grams_1 in bigrams_2:\n",
        "                    common.append(grams_1)\n",
        "            if not common:\n",
        "              return 0\n",
        "            else:\n",
        "              return len(common)\n",
        "\n",
        "        # Add new columns with number of common ngrams\n",
        "        print(\"creating ngrams columns ....\")\n",
        "        start_ngrams = time.time()\n",
        "        self.df_merged['ngrams_search_and_title'] = self.df_merged['product_all_information'].map(lambda x: common_ngrams(x.split('\\t')[0], x.split('\\t')[1], 2))\n",
        "        self.df_merged['ngrams_search_and_description'] = self.df_merged['product_all_information'].map(lambda x: common_ngrams(x.split('\\t')[0], x.split('\\t')[2], 2))\n",
        "        self.df_merged['brand_helper'] = self.df_merged['brand_helper'].map(lambda x: common_ngrams(x.split('\\t')[0], x.split('\\t')[2], 2))\n",
        "        end_ngrams = time.time()\n",
        "        print(\"ngrams calculation finished in \", (end_ngrams - start_ngrams), \"seconds\")\n",
        "\n",
        "        return self.df_merged\n",
        "    \n",
        "\n",
        "    def train_and_predict(self, compare_many=None, grid=True):\n",
        "        self.df_merged = self.feature_engineering()\n",
        "        print(self.df_merged.head(2))\n",
        "        # Drop the unecessary columns\n",
        "        df = self.df_merged.drop(columns=['search_term','product_title','product_description','product_all_information','product_uid','brand', 'brand_helper'],axis=1)\n",
        "        print(df.info())\n",
        "\n",
        "        df_train = df.iloc[:self.len_train]\n",
        "        # df_train.reset_index(drop=True, inplace=True)\n",
        "        print(df_train.shape)\n",
        "        print(df_train.head(5))\n",
        "\n",
        "        df_test = df.iloc[self.len_train:]\n",
        "        # df_test.reset_index(drop=True, inplace=True)\n",
        "        print(df_test.shape)\n",
        "        id_test = df_test['id'] # keep this for exporting to csv\n",
        "        print(id_test.shape)\n",
        "        print(df_test.head(5))\n",
        "\n",
        "        X = df_train.drop(columns=['relevance', 'id']) # drop label and id\n",
        "        y = df_train['relevance']\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                            y,\n",
        "                                                            train_size=0.7,\n",
        "                                                            test_size=0.3,\n",
        "                                                            random_state=42,\n",
        "                                                            )\n",
        "        print('X_train shape ', X_train.shape)\n",
        "        print('X test shape ', X_test.shape)\n",
        "\n",
        "        if compare_many:\n",
        "            dict_regressors = {\"Linear\": LinearRegression(),\n",
        "                              \"Ridge\": Ridge(),\n",
        "                              \"SVR\": SVR(),\n",
        "                              \"RF\": RandomForestRegressor(),\n",
        "                              \"GBR\": GradientBoostingRegressor(),\n",
        "                              \"XGBoost\": XGBRegressor(),\n",
        "                              }\n",
        "\n",
        "            for name, model in dict_regressors.items():\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred = model.predict(X_test)\n",
        "                mse = mean_squared_error(y_pred, y_test)\n",
        "                rmse = np.sqrt(mse)\n",
        "                print(name, ' RMSE is: %.4f' % rmse)\n",
        "\n",
        "        elif grid:\n",
        "            # create a metric as RMSE is not provided in the scoring parameter in cross-validation\n",
        "            def fmean_squared_error(ground_truth, predictions):\n",
        "                fmean_squared_error = mean_squared_error(ground_truth, predictions)**0.5\n",
        "                return fmean_squared_error\n",
        "            RMSE = make_scorer(fmean_squared_error, greater_is_better=False)\n",
        "\n",
        "            gb = GradientBoostingRegressor(random_state=12345)\n",
        "\n",
        "            # Set the parameter values for GridSearch\n",
        "            param_grid = {'n_estimators': [50, 100],\n",
        "                          'max_depth': [1, 2]\n",
        "                         }\n",
        "            model = GridSearchCV(estimator= gb,\n",
        "                                param_grid= param_grid,\n",
        "                                n_jobs= -1,\n",
        "                                cv= 10, \n",
        "                                verbose= 20,\n",
        "                                scoring= RMSE)\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            print(\"GB: Best parameters found by grid search:\", model.best_params_)\n",
        "            print(\"Gradient Boosting's best CV score: %.4f\" % model.best_score_)\n",
        "\n",
        "            print('-----------------------------------------------------------')\n",
        "\n",
        "            xgboost = XGBRegressor(random_state=1234)\n",
        "            param_grid = {'min_child_weight': [ 5],\n",
        "                          'max_depth': [2, 4, 6, 8, 10, 12]\n",
        "                         }\n",
        "            model = GridSearchCV(estimator= xgboost,\n",
        "                                param_grid= param_grid,\n",
        "                                n_jobs= -1,\n",
        "                                cv= 10, \n",
        "                                verbose= 20,\n",
        "                                scoring= RMSE)\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            print(\"GB: Best parameters found by grid search:\", model.best_params_)\n",
        "            print(\"Gradient Boosting's best CV score: %.4f\" % model.best_score_)\n",
        "            # predictions = pd.DataFrame({\"id\": id_test,\n",
        "            #                     \"relevance\": y_pred})\n",
        "            # predictions.to_csv('predictions_rf.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqCtUyhbT2pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "settings = {\n",
        "    'path_to_files': '/content/drive/My Drive/Colab Notebooks/', # path_to_files = \"/content/drive/My Drive/NLP\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDjhx5fGT2pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rsp = RelevanceScorePrediction(settings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "vIdOM6tHT2p0",
        "colab_type": "code",
        "outputId": "e9b4a0bf-2b7a-45cd-ce1a-c92272f0a0f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rsp.train_and_predict(compare_many=True)\n",
        "# rsp.train_and_predict(grid=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of train is: (74067, 5)\n",
            "The info of train is: \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74067 entries, 0 to 74066\n",
            "Data columns (total 5 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   id             74067 non-null  int64  \n",
            " 1   product_uid    74067 non-null  int64  \n",
            " 2   product_title  74067 non-null  object \n",
            " 3   search_term    74067 non-null  object \n",
            " 4   relevance      74067 non-null  float64\n",
            "dtypes: float64(1), int64(2), object(2)\n",
            "memory usage: 2.8+ MB\n",
            "None\n",
            "The len_train is: \n",
            "74067\n",
            "\n",
            " The shape of test is: (166693, 4)\n",
            "The info of test is: \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 166693 entries, 0 to 166692\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             166693 non-null  int64 \n",
            " 1   product_uid    166693 non-null  int64 \n",
            " 2   product_title  166693 non-null  object\n",
            " 3   search_term    166693 non-null  object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 5.1+ MB\n",
            "None\n",
            "\n",
            " The shape of product description is:  (124428, 2)\n",
            "The info of product description is: \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 124428 entries, 0 to 124427\n",
            "Data columns (total 2 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   product_uid          124428 non-null  int64 \n",
            " 1   product_description  124428 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.9+ MB\n",
            "None\n",
            "\n",
            " The shape of product attributes is: \n",
            " (2044803, 3)\n",
            "The null values of product attributes before drop are: \n",
            " product_uid     155\n",
            "name            155\n",
            "value          2284\n",
            "dtype: int64\n",
            "The null values of product attributes after drop are: \n",
            " product_uid       0\n",
            "name              0\n",
            "value          2129\n",
            "dtype: int64\n",
            "The shape of train-test dataframe is:  (240760, 5)\n",
            "The shape of product_brand is:  (86250, 2)\n",
            "The shape of train_test_brands is:  (240760, 6)\n",
            "The info of train_test_brands is: \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 240760 entries, 0 to 240759\n",
            "Data columns (total 6 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   id             240760 non-null  int64  \n",
            " 1   product_uid    240760 non-null  int64  \n",
            " 2   product_title  240760 non-null  object \n",
            " 3   search_term    240760 non-null  object \n",
            " 4   relevance      74067 non-null   float64\n",
            " 5   brand          194623 non-null  object \n",
            "dtypes: float64(1), int64(2), object(3)\n",
            "memory usage: 12.9+ MB\n",
            "None\n",
            "The info of train_test_brands after filling null values is: \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 240760 entries, 0 to 240759\n",
            "Data columns (total 6 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             240760 non-null  int64 \n",
            " 1   product_uid    240760 non-null  int64 \n",
            " 2   product_title  240760 non-null  object\n",
            " 3   search_term    240760 non-null  object\n",
            " 4   relevance      240760 non-null  object\n",
            " 5   brand          240760 non-null  object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 12.9+ MB\n",
            "None\n",
            "Perform text corrections with regex\n",
            "product_title...\n",
            "brand...\n",
            "product_description...\n",
            "initial: \n",
            " BEHR Premium Textured DECKOVER is an innovative solid color coating. It will bring your old, weathered wood or concrete back to life. The advanced 100% acrylic resin formula creates a durable coating for your tired and worn out deck, rejuvenating to a whole new look.  For the best results, be sure to properly prepare the surface using other applicable BEHR products displayed above.California residents: see&nbsp;Proposition 65 informationRevives wood and composite decks, railings, porches and boat docks, also great for concrete pool decks, patios and sidewalks100% acrylic solid color coatingResists cracking and peeling and conceals splinters and cracks up to 1/4 in.Provides a durable, mildew resistant finishCovers up to 75 sq. ft. in 2 coats per gallonCreates a textured, slip-resistant finishFor best results, prepare with the appropriate BEHR product for your wood or concrete surfaceActual paint colors may vary from on-screen and printer representationsColors available to be tinted in most storesOnline Price includes Paint Care fee in the following states: CA, CO, CT, ME, MN, OR, RI, VT\n",
            "after regex: \n",
            " BEHR Premium Textured DECKOVER is an innovative solid color coating. It will bring your old, weathered wood or concrete back to life. The advanced 100% acrylic resin formula creates a durable coating for your tired and worn out deck, rejuvenating to a whole new look.  For the best results, be sure to properly prepare the surface using other applicable BEHR products displayed above. California residents: see&nbsp; Proposition 65 information Revives wood and composite decks, railings, porches and boat docks, also great for concrete pool decks, patios and sidewalks100% acrylic solid color coating Resists cracking and peeling and conceals splinters and cracks up to 1/4 in. Provides a durable, mildew resistant finish Covers up to 75 sq. ft. in 2 coats per gallon Creates a textured, slip-resistant finish For best results, prepare with the appropriate BEHR product for your wood or concrete surface Actual paint colors may vary from on-screen and printer representations Colors available to be tinted in most stores Online Price includes Paint Care fee in the following states: CA, CO, CT, ME, MN, OR, RI, VT\n",
            "Simple regex finished in  11.23389220237732 seconds\n",
            "Measurement unit correction...\n",
            "search term...\n",
            "product_title...\n",
            "brand...\n",
            "product_description...\n",
            "Measurement unit correction finished in  12.014158725738525 seconds\n",
            "Removing stopwords...\n",
            "The stopwords are:  ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "search_term...\n",
            "product_title...\n",
            "brand...\n",
            "product_description...\n",
            "behr premium textured deckover innovative solid color coating . bring old , weathered wood concrete back life . advanced 100 % acrylic resin formula creates durable coating tired worn deck , rejuvenating whole new look . best results , sure properly prepare surface using applicable behr products displayed . california residents : see & nbsp ; proposition 65 information revives wood composite decks , railings , porches boat docks , also great concrete pool decks , patios sidewalks100 % acrylic solid color coating resists cracking peeling conceals splinters cracks 1/4 . provides durable , mildew resistant finish covers 75 sq.ft . . 2 coats per gal . creates textured , slip-resistant finish best results , prepare appropriate behr product wood concrete surface actual paint colors may vary on-screen printer representations colors available tinted stores online price includes paint care fee following states : ca , co , ct , , mn , , ri , vt\n",
            "Stopwords removal finished in  282.1912114620209 seconds\n",
            "----------------------------------------------------\n",
            "Removing punctuations...\n",
            "The punctuations are:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "search_term...\n",
            "product_title...\n",
            "brand...\n",
            "product_description...\n",
            "behr premium textured deckover innovative solid color coating  bring old  weathered wood concrete back life  advanced 100  acrylic resin formula creates durable coating tired worn deck  rejuvenating whole new look  best results  sure properly prepare surface using applicable behr products displayed  california residents  see  nbsp  proposition 65 information revives wood composite decks  railings  porches boat docks  also great concrete pool decks  patios sidewalks100  acrylic solid color coating resists cracking peeling conceals splinters cracks 14  provides durable  mildew resistant finish covers 75 sqft   2 coats per gal  creates textured  slipresistant finish best results  prepare appropriate behr product wood concrete surface actual paint colors may vary onscreen printer representations colors available tinted stores online price includes paint care fee following states  ca  co  ct   mn   ri  vt\n",
            "Punctuation removal finished in  1.8409812450408936 seconds\n",
            "----------------------------------------------------\n",
            "Performing simple stemming...\n",
            "search_term...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc0ulGkQrGGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZcI-sVyxtF8u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "eaceaa2d-cc83-43c4-eada-2139972fc268"
      },
      "source": [
        "rf = RandomForestRegressor(random_state=0)\n",
        "\n",
        "# Set the parameter values for GridSearch\n",
        "param_grid = {'max_samples': [0.1, 0.2, 0.4],\n",
        "              'n_estimators': [100, 200, 300],\n",
        "              'min_samples_split': [2, 4, 6]\n",
        "             }\n",
        "\n",
        "model = GridSearchCV(estimator= rf,\n",
        "                    param_grid= param_grid,\n",
        "                    n_jobs= -1,\n",
        "                    cv= 10, \n",
        "                    verbose= 20,\n",
        "                    scoring= RMSE\n",
        "                    )\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"RF: Best parameters found by grid search:\", model.best_params_)\n",
        "print(\"Random Forest's best CV score: %.4f\" % model.best_score_)\n",
        "\n",
        "# # Gradient Boosting regressor. It has not been used in conjunction to Bagging regressor\n",
        "# gb = GradientBoostingRegressor(random_state=0)\n",
        "# gb.fit(X_train, y_train)\n",
        "# y_pred = gb.predict(X_test)\n",
        "\n",
        "# model = GridSearchCV(estimator= clf,\n",
        "#                                 param_grid= param_grid,\n",
        "#                                 n_jobs= -1,\n",
        "#                                 cv= 2, \n",
        "#                                 verbose= 20,\n",
        "#                                 scoring= RMSE)\n",
        "# model.fit(X_train, y_train)\n",
        "# print(\"RF: Best parameters found by grid search:\", model.best_params_)\n",
        "# print(\"Random Forest's best CV score: %.4f\" % model.best_score_)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-06bc978b33aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                     )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RMSE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sNVwwJXbtbZG"
      },
      "source": [
        "3. Bagging Regressor to improve Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aud7y-wttePq",
        "colab": {}
      },
      "source": [
        "# clf = BaggingRegressor(base_estimator= rf, random_state=1)\n",
        "# clf.fit(X_train, y_train)\n",
        "# y_pred = clf.predict(X_test)\n",
        "\n",
        "# # Set the parameter values for GridSearch\n",
        "# param_grid = {'max_samples': [0.1, 0.2],\n",
        "#               'n_estimators': [10, 100, 150],\n",
        "#               'min_samples_split': [2, 4, 6]\n",
        "#              }\n",
        "\n",
        "# model = GridSearchCV(\n",
        "#     estimator= rf,\n",
        "#     param_grid= param_grid,\n",
        "#     n_jobs= -1,\n",
        "#     cv= 10, \n",
        "#     verbose= 20,\n",
        "#     scoring= RMSE\n",
        "# )\n",
        "\n",
        "# model.fit(X_train, y_train)\n",
        "# y_pred = model.predict(X_test)\n",
        "# print(\"RF: Best parameters found by grid search:\", model.best_params_)\n",
        "# print(\"Random Forest's best CV score: %.4f\" % model.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzNbcBbIqbV8",
        "colab_type": "code",
        "outputId": "d01a7013-ccec-4d4d-d95d-877643453b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "descr = pd.read_csv('/content/drive/My Drive/Colab Notebooks/product_descriptions.csv', header=0)\n",
        "pd.options.display.max_rows = 100\n",
        "pd.set_option('max_colwidth', 9000)\n",
        "print(descr[descr['product_description'].str.contains(\"oz\")]['product_description'])\n",
        "\n",
        "# descr['product_description'].apply(lambda x: ngrams(x.lower().split(), 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11        The 96 in. wide Caramel Simple Weave Rollup Bamboo Shade adds a unique casual style to any room. Replace your white window blinds with this versatile natural shade and add warm comforting tones to your decor. This cozy natural shade (also called a bamboo blind or bamboo shade) is composed of natural environmental friendly materials and installs easily with simple hooks. It has a textured caramel finish that complements many hardwood floor and furniture styles, and looks great with a jute or sisal rug. Bamboo flatstick slats are held together by a dark-weave cord, which gently roll up when more sunlight is needed. Textured natural shades are stylishly complementary to coastal, lake, beach, mountain, cottage, or traditional styles of interior decorating. If you plan to use this natural shade outdoors on the porch or deck, you can simply unhook it and bring it indoors easily during the off season if you choose. Shade sizes 60 inch wide and larger roll up for easy lifting. Sizes narrower than 60 in. wide fold up roman style. All sizes install easily with simple hooks.96 in. W x 72 in. LActual Blind Width is 96 in.No deductions are made to this blind - the actual width of this blind is the same as width orderedFor an Inside Mount, fits windows: 96 in. WideFor an Outside mount, order the width of the overall area to be coveredShade provides privacy and the perfect amount of lightShips within 2-3 business daysBamboo slats held by a dark weave cord for warm tones and natural beautyNatural materials may vary slightly in colorRolls up easily when you want to let in additional sunlightInstalls in minutes with the included simple hook hardwareFilters out light for energy-efficient insulationIncludes a 6 in. matching valance, a color coordinated weaving thread and pull cordsDecorating Tip: Add depth and texture to a room by layering textured window shades under curtain panels or cornice boardsDecorating Tip: To make your windows look larger, you can hang this shade outside the molding or up to the ceilingNot sure what size to buy? Click here to download a printable window treatment measuring guide!WARNING: The cords on this product present a potential strangulation hazard. For child safety, consider cordless alternatives or products with inaccessible cords. To access a copy of the warning label, see additional images.\n",
            "20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Installed in parks and backyards across the globe, Rain Bird's 1800 Series is the #1 selling commercial-grade pop-up sprinkler in the world. Chosen for its reliability, heavy-duty materials and versatility, the 1800 Series offers a broad selection of spray heads for watering shrubs, small lawns and irregularly shaped planting areas. Precision spray heads and nozzles customize your watering system to cover virtually any configuration of lawn or garden - not the sidewalk or driveway. The 1800 Series offers Rain Bird's patented pop-up mechanism for out-of-sight retraction into the lawn when not in operation. A wide choice of nozzles provides full circle, partial circle coverage or infinite pattern adjustment for optimum head-to-head coverage.Spray distance from 8 ft. to 15 ft.Patented close-in watering for most efficient uniform water coverage, resulting in the elimination of dry brown spotsHeavy-duty stainless-steel spring helps ensure flush retractionPop-up sprinkler head features a top-adjustment screw to adjust the spray distance4 in pop-up heightDual spray technology for water efficiencyReduces water waste in windy conditionsNote: Product may vary by store.\n",
            "61                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Evolution Series garbage disposals are the world's most advanced food garbage disposals . From the powerful induction motors with cutting edge grind technologies to the top-of-the-line sound reducing technologies, the Evolution Select Continuous Feed garbage Disposal delivers exceptional performance- a perfect solution for smaller households or kitchens with restricted cabinet space.Quick Lock sink mount allows for easy installation and disposer replacement5/8 HP Dura-Drive motor provides quiet operation and long life34.6 oz. grind chamber with stainless steel grind components offers durability in a compact sizeMultiGrind technology quickly grinds almost any food wasteSoundSeal technology delivers Quiet performance versus a standard disposer4-year We Come to You In-Home Service Warranty covers repair or replacement by an authorized dealerPower cord is sold separately for installations where a power outlet is present, most installations are direct wired and do not use a power cordMade in the USA and available only at The Home DepotHome Depot Protection Plan:\n",
            "68                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The Shark Rotator Slim-Light Lift-Away is an extremely light lift-away with a portable pod and a shoulder strap to make cleaning in your home easy. Armed with advanced swivel steering for excellent control when maneuvering around furniture, this vacuum has Anti-Allergen Complete Seal Technology + HEPA that traps 99.99% of dust and allergens inside the vacuum. Combined with 2 foam filters, this dust containment system helps keep dust and allergy-causing agents from escaping back into the air. The deluxe motorized brush roll can be turned on or off, providing powerful performance on both carpets and bare floors. The vacuum includes a crevice tool, wide upholstery tool, dusting brush, shoulder strap and accessory bag for convenient storage. It also includes a Dust-Away attachment that enhances bare floor cleaning. Based on ASTM F1977 of particles between 0.3 and 0.5 microns.California residents: see&nbsp;Proposition 65 informationNever Loses Suction technology2-in-1 Lift-Away technology with shoulder strapPremium floor nozzle with headlightsAnti-Allergen Complete Seal technologyDust-away hard-floor attachment for powerful bare floor cleaning\n",
            "78                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    The Frigidaire 18 cu. ft. Top Freezer has 2 Full-Width Glass Shelves and 2 Humidity Control Crisper Drawers for storing fruits and vegetables. Equipped with bright lighting to keep contents clearly visible. Freezer has a half width shelf for flexible storage options as well as two full-width door racks.Optional icemaker eliminates the need to fill ice trays and ensures you have a steady supply of ice on handSingle knob control inside the refrigerator for easy temperature management2 Full-width sliding glass shelves in the fresh food compartment help you to stay organized2 Humidity-Controlled Crisper Drawers keep your fruits and vegetables freshDoor storage includes 3 Full-width racks that give you room for larger items like a gallon of milkLarge 14.1 cu. ft. Fresh Food Capacity has the space to keep foods organized while 3.98 cu. ft. Freezer Capacity gives you room for storing all your frozen foods2 Full-width freezer door racks and 1 half-width shelf gives you more usable space and better organizationDairy compartment with a clear dairy door is perfect for storing butter and cheesesColor coordinated cabinet, door, and handles give you a refined lookBright lighting makes it easy to see what's insideA two-door refrigerator model that features the freezer on top and the refrigerator on the bottomClick Here for details on the services included with Delivery & Basic Hook-up and Installation options for Major Appliances\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
            "124328                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Everything you need to protect yourself from bed bugs while travelling. The Bed Bug Travel Kit contains everything you need to protect yourself while travelling and to prevent bed bugs from returning home with you. The Kit specializes in mimicking your sleeping body by generating carbon dioxide and heat to actively attract bed bugs from their hiding places and into the traps.Perfect for frequent travelers and vacationersPlace on hotel bed, furniture or bags to quickly identify a potential bed bug infestationQuick-response kit actively attracts bed bugs from their hiding spot by generating heat and carbon dioxide to mimic your sleeping bodyTakes one minute to set up and quickly alerts you to potential bed bug activityIncludes bed bug killing spray for immediately killing of bed bugs and preventing bed bugs from spreading home with youIncludes dissolving laundry bag - when travelling, simply place all dirty clothes into bag and place directly in wash once you return home, any bed bugs who have hitch hiked with you home will be killed in the washAll contents in kit are safe and legal for travelling on planeKit can be used to detect and eliminate bed bugs in - beds, box springs, mattresses-couches/sofas-chairs, side tables and night stands-luggage, pursesIncludes nylon travel bagContents of kit include - 2 x quick-response kit (carbon dioxide generator, heat pads and detection traps x 2) - replaceable non-toxic glue cartridges x 6-bed bug prevention spray (3.0 fl. oz.) x 1-dissolving laundry bag x 1-LED flash light x 1 -latex free protective glove x 2-nylon carrying case x 1-instructional manual\n",
            "124352                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Woolite 32 fl. oz. Pet plus Oxygen Stain and Odor Remover effectively removes tough pet stains and odors and offers triple-action cleaning against the toughest pet odors. It also has a patented Pherobloc technology that discourages pets from re-soiling the same area. Safe for use on carpet, upholstery and water-safe surfaces.Eliminates pet stain and offensive odorsOxygen action even removes colored stains caused by dyes in pet foodNon-toxicConvenient spray bottleTargets and neutralizes bad odors and smells in carpetCleans pet stains such as vomit, urine and feces from carpetRemoves and gets rid of blood stains in carpet\n",
            "124365                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The Rust-Oleum Stops Rust 32 oz. Gloss Protective Enamel Paint is designed for use on a variety of materials including wood, metal, concrete and masonry. The versatile paint provides coverage for up to 100 sq. ft. and dries to a glossy finish. The paint helps protect against corrosion and rust. Also, it can be used both indoors and outdoors for versatility.California residents: see&nbsp;Proposition 65 informationApplies easily with a good quality brush, roller or spray gunOil-based formula which provides superior rust-prevention, coverage and durabilityGloss finishDries to the touch in as little as 4 hoursCovers up to 100 sq. ft. for your convenienceRust-preventive finish for industrial applicationsProvides lasting protection and beauty for your projectsCleans up with mineral spiritsOnline Price includes Paint Care fee in the following states: CA, CO, CT, MN, OR, RI, VT\n",
            "124393                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Bridging the gap between form and function, and proving that sometimes less is more, Smart Divide kitchen sinks feature an innovative low-profile divider to better accommodate large pots and help keep water where it belongs. This durable Langlade Smart Divide undercounter mount kitchen sink, constructed of KOHLER Cast Iron, will stand up to years of rugged use while maintaining its rich, lustrous sheen. Combined with the Evolution Supreme garbage disposal, this bundle offers exceptional quality at an affordable price. Evolution Series garbage disposals are the worlds most advanced food garbage disposals. From the powerful induction motors with cutting edge grind technologies to the top-of-the-line sound reducing technologies, the Evolution Supreme Continuous Feed garbage Disposal delivers exceptional performance where it matters most.Smart Divide features a lower bowl divider that increases workspace and versatilityEach basin measures 15 in. L x 18-3/8 in. WConstructed of KOHLER Cast IronBasin depth of 9 in.Undercounter installationDisposer's Quick Lock sink mount allows for easy installation and replacement1 HP  Dura-Drive motor provides quiet disposer operation and long lifeDisposer features a 40 oz. grind chamber with stainless steel grind componentsInSinkErator's MultiGrind technology quickly grinds almost any food wasteDisposer's SoundSeal technology delivers Ultra Quiet performance enabling you to hold a conversation with normal voices in the same roomAntimicrobial Quiet Collar sink baffle is easily removed for cleaning and  helps inhibit growth of odor-causing bacteriaDisposer's power cord is sold separately for installations where a power outlet is present, most installations are direct wired and do not use a power cord\n",
            "124418                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Paracord is ideal for camping, hiking and other outdoor activities. You can braid a survival bracelet from Paracord and unravel it when cordage is needed. It has a great combination of strength and durability for a lightweight rope. Some of the dozens of practical uses for Paracord include: making a tarp ridgeline, securing equipment to a backpack or a vehicle, making a shelter, replacing shoelaces, making a clothesline, hanging food while camping, marking a trail and making an emergency tourniquet. Made with a dual polypropylene/nylon construction. Always keep at least 50 ft. of Paracord on hand.California residents: see&nbsp;Proposition 65 informationMake your own Paracord survival bracelet to ensure your Paracord is always there when you need it mostParacord is a must have for anyone who enjoys the outdoors1001 uses for Paracord including shelter making, clotheslines, slings for gear or weapons and household usesContains 1 or more of: nylon, polypropylene, polyesterThe Cordage Institute defines Working Load Limit (WLL) as the working load that must not be exceeded for a particular application as established by a regulatory or standards setting agency. This is different than the Breaking Strength of a rope, which is the force at which a rope will break. Working Load Limit is always a lower value than the Breaking Strength of a rope.\n",
            "Name: product_description, Length: 5178, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROfhMRc0MJA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}